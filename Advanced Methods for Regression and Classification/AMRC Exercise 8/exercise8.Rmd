---
title: "Exercise 8"
author: "Konstantinos Vakalopoulos 12223236"
date: "2023-01-11"
output: pdf_document
header-includes:
  - \usepackage{floatrow}
  - \floatsetup[figure]{capposition=bottom}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Premilinary work

First, the data (hcvdat1.csv) were loaded

```{r, eval = TRUE}
bank <- read.csv2("C:/Users/vaka1/Desktop/bank.csv") #must be modified
```

and missing values were omitted.

```{r, eval = TRUE}
bank <- na.omit(bank)
```

We transform all the character variables to factors and all int variables to numeric. Furthermore, the value "yes" was replaced by 1 and the value "no" to zero.

```{r, eval = TRUE}
bank$job <- as.factor(bank$job)
bank$marital <- as.factor(bank$marital)
bank$education <- as.factor(bank$education)
bank$default <- as.factor(bank$default)
bank$housing <- as.factor(bank$housing)
bank$loan <- as.factor(bank$loan)
bank$contact <- as.factor(bank$contact)
bank$month <- as.factor(bank$month)
bank$poutcome <- as.factor(bank$poutcome)


bank$y <- ifelse(bank$y=="yes",1,0)
bank$y <- as.factor(bank$y)
```

```{r, eval = TRUE}
bank$age <- as.numeric(bank$age)
bank$balance <- as.numeric(bank$balance)
bank$day <- as.numeric(bank$day)
bank$duration <- as.numeric(bank$duration)
bank$campaign <- as.numeric(bank$campaign)
bank$pdays <- as.numeric(bank$pdays)
bank$previous <- as.numeric(bank$previous)
```

Thus, for addition information about the data, the following commands were used

```{r, eval = TRUE}
summary(bank)
str(bank)
```

Below, it is presented the number of no and yes for the response variable y using the library ggplot2. Based on the histogram, it can be seen that the data are heavily imbalanced

```{r results='hide', message=FALSE, warning=FALSE}
library(ggplot2)
```

```{r, eval = TRUE, fig.width=6,fig.height=4, fig.align="center", fig.cap="Frequency of the response variable", fig.pos="H",warning=FALSE}
ggplot(bank, aes(x=y)) +
  geom_histogram(stat="count")
```

More information about the data are presented to the plots using the library Hmisc.

```{r results='hide', message=FALSE, warning=FALSE}
library(Hmisc)
```

```{r, eval = TRUE, fig.width=7,fig.height=6, fig.align="center", fig.cap="Histograms of the numeric variables", fig.pos="H",warning=FALSE}
hist.data.frame(bank[,which(sapply(bank, is.numeric)==TRUE)])
```

```{r, eval = TRUE, fig.width=7,fig.height=6, fig.align="center", fig.cap="Frequencies of the categorical variables", fig.pos="H",warning=FALSE}
hist.data.frame(bank[,which(sapply(bank, is.numeric)==FALSE)])
```


## Question 1(a)

The bank data set was split into 2/3 train and 1/3 test randomly.

```{r, eval = TRUE}
set.seed(12223236)
n <- nrow(bank)
train <- sample(1:n,round(n*2/3))
test <- (1:n)[-train]
```

In R, from the package rpart, the function rpart() was used in order to compute the initial tree.

```{r, eval = TRUE}
library(rpart)
model.tree <- rpart(y~.,data=bank, subset=train)
```

## Question 1(b)

After creating the initial tree, the functions plot() and text() were used for the representation of the tree. 

```{r, eval = TRUE, fig.width=7,fig.height=6, fig.align="center", fig.cap="Initial Tree", fig.pos="H",warning=FALSE}
plot(model.tree)
text(model.tree)
```

However, there are wrong labels in the tree. Thus, for convenient purposes, the function prp() from the package rpart.plot was used for the tree representation. 

```{r, eval = TRUE, fig.width=7,fig.height=6, fig.align="center", fig.cap="Initial Tree", fig.pos="H",warning=FALSE}
rpart.plot::prp(model.tree)
```
The tree model was created using only 4 variables: duration, poutcome, month and job. The depth of the tree is 4. We start from the root node, which is the variable duration. This indicates that the variable duration is significant to the model. If duration is lower than 386 we move to the node where we check if the variable poutcome is equal to "failure" or "other" or "unknown". If duration is greater or equals to 386 we move to next node on the right where we check again the value of the variable duration. We continue the same procedure until we reach the leaf nodes. The leaf nodes are responsible for the final classification of the observations. Thus, for the classification of unknown observations, we follow the branches/edges of the tree based, of course, on the conditions/internal nodes until we reach the leaf nodes where the final classification takes place. 


## Question 1(c)

In this question of the exercise the class variable "y" for test set was predicted and then the misclassification rate was calculated. 

```{r, eval = TRUE}
predicted.classes <- predict(model.tree,newdata=bank[test,], type="class")
actual.classes <- bank[test,]$y
TAB <- table(actual.classes,predicted.classes)
TAB

misclassification.error <- 1-sum(diag(TAB))/sum(TAB)
cat("The misclassification rate is: ", misclassification.error)
```


## Question 1(d)

Cross validation was implemented by using the functions printcp() and plotcp() in order to find the optimal cost complexity for a smaller pruned tree. 

```{r, eval = TRUE}
printcp(model.tree)
optimal.cp <- model.tree$cptable[which.min(model.tree$cptable[,'xerror']),'CP']
optimal.cp
```

The printcp() function provide the cross validation error for each split based on different values of the cost complexity parameter. The one with least cross-validated error (xerror) is the optimal value of CP given by the printcp() function. In our case, the optimal cost complexity is: 0.01895044.

```{r, eval = TRUE, fig.width=7,fig.height=6, fig.align="center", fig.cap="Cost Complexity", fig.pos="H",warning=FALSE}
plotcp(model.tree)
```

A graphical depiction of the cross-validated error summary is provided via plotcp(). To show the deviation, the cp values are plotted against the geometric mean until the smallest value is attained. 

## Question 1(e)

Based in the question 1(d) the optimal cost complexity is 0.0189 This specific cp value was used for pruning the initial tree using the function prune().

```{r, eval = TRUE}
model.tree.pruned <- prune(model.tree,cp=optimal.cp)
```

For the tree visualization, the function prp(), as mentioned above, was used. 

```{r, eval = TRUE, fig.width=7,fig.height=6, fig.align="center", fig.cap="Pruned Tree", fig.pos="H",warning=FALSE}
rpart.plot::prp(model.tree.pruned)
```
The pruned tree is noticeable smaller, with depth equals to 3, compared to the initial tree. The tree model uses only two variables (duration and poutcome) where the variable duration still remains the most important variable. This is due to fact that this variables is in the root of the pruned tree. 


## Question 1(f)

In this question of the exercise the class variable "y" for test set was predicted and then the misclassification rate was calculated for the pruned tree.

```{r, eval = TRUE}
predicted.classes <- predict(model.tree.pruned,newdata=bank[test,], type="class")
actual.classes <- bank[test,]$y
TAB <- table(actual.classes,predicted.classes)
TAB

misclassification.error <- 1-sum(diag(TAB))/sum(TAB)
cat("The misclassification rate is: ", misclassification.error)
```
It is observed that the misclassification rate has been decreased from 0.1088 to 0.0995. Also, based on the two confusion matrices 14 observations from the minority class "1" were predicted correctly from the pruned tree compared to the initial full tree. 

## Question 1(g)

There are two techniques that can possibly reduce the misclassification rate. The first strategy is to split the data using the stratification technique. With this technique the data set split into train and test set maintaining
the same proportions of samples in each class as shown in the original data set. Below, using the caret package, the data were split using the stratification.

```{r, eval = TRUE}
model.tree <- rpart(y~.,data=bank, subset=train)
predicted.classes <- predict(model.tree,newdata=bank[test,], type="class")
actual.classes <- bank[test,]$y
TAB <- table(actual.classes,predicted.classes)

misclassification.error <- 1-sum(diag(TAB))/sum(TAB)
cat("The misclassification rate for the intitial tree is: ", misclassification.error)
cat("\n")
cat("The misclassification rate for the intitial tree for the yes clients is: ", 
    1 - TAB[2,2]/(TAB[1,2]+TAB[2,1]+TAB[2,2]))
cat("\n")

set.seed(12223236)
train_str <- caret::createDataPartition(bank$y, times = 1,p=2/3, list=F) #stratified separation
test_str <- (1:n)[-train_str]

model.tree.statified <- rpart(y~.,data=bank, subset=train_str)

predicted.classes <- predict(model.tree.statified,newdata=bank[test,], type="class")
actual.classes <- bank[test,]$y
TAB <- table(actual.classes,predicted.classes)

misclassification.error <- 1-sum(diag(TAB))/sum(TAB)
cat("The misclassification rate for the stratified tree is: ", misclassification.error)
cat("\n")
cat("The misclassification rate for the stratified tree for the yes clients is: ", 
    1 - TAB[2,2]/(TAB[1,2]+TAB[2,1]+TAB[2,2]))
```
Therefore, the overall and the "yes" clients misclassification rate has been slightly decreased. 

The second strategy to assign weights in each observation based on the class that it belongs. Thus, the weights will depend mainly from the class of the observation. Basically, the weight will be small if the observation belongs to majority class and high if the observation belongs to the minority class.The entire idea of the weights is to penalize the minority
class for misclassifying itself by increasing class weight while simultaneously decreasing class weight for the
majority class.

The formula for the weight assignments is: wj=n_samples / (n_classes * n_samplesj), where wj is the weight for each class(j signifies the class), n_samples the total number of samples or rows in the dataset, n_classes the total number of unique classes in the target, n_samplesj is the total number of rows of the respective class. Thus the final weights are for the two classes:

```{r, eval = TRUE}
w0 <- length(train)/(2*table(bank[train,]$y)[1]) #weight for the 0 or class "no"
w1 <- length(train)/(2*table(bank[train,]$y)[2]) #weight for the 1 or class "yes"
w <- ifelse(bank[train,]$y == 1, w1, w0)

model.tree.weights <- rpart(y~.,data=bank[train,], weights = w)

predicted.classes <- predict(model.tree.weights,newdata=bank[test,], type="class")
actual.classes <- bank[test,]$y
TAB <- table(actual.classes,predicted.classes)

misclassification.error <- 1-sum(diag(TAB))/sum(TAB)
cat("The misclassification rate for the weighted tree is: ", misclassification.error)
cat("\n")
cat("The misclassification rate for the weighted tree for the yes clients is: ", 
    1 - TAB[2,2]/(TAB[1,2]+TAB[2,1]+TAB[2,2]))
```
In conclusion, the "yes" clients misclassification rate has been decreased. However, the overall misclassification rate has been increased up to 13% which is a huge a difference compared to the initial tree. 


## Question 2(a)

From the package randomForest, the function randomForest() was used in order to create a model based on the train set. also, the misclassification rate was calculated.

```{r, eval = TRUE}
library(randomForest)

model.random.forest <- randomForest(y~.,data=bank, subset=train)


predictions <- predict(model.random.forest,newdata=bank[test,], type="class")
actual <- bank[test,]$y
TAB.forest <- table(actual,predictions)
TAB.forest

misclassification.error.forest <- 1-sum(diag(TAB.forest))/sum(TAB.forest)
cat("The misclassification rate is: ", misclassification.error.forest)
cat("\n")
cat("The misclassification rate for the yes clients is: ", 
    1 - TAB[2,2]/(TAB[1,2]+TAB[2,1]+TAB[2,2]))
```

## Question 2(b)

The option importance=TRUE in the function randomForest() was used. Furthermore, the plot and the varImpPlot was used.
```{r, eval = TRUE}
model.random.forest <- randomForest(y~.,data=bank, subset=train,importance = TRUE)
```

```{r, eval = TRUE, fig.width=7,fig.height=6, fig.align="center", fig.cap="Random Forest Importance", fig.pos="H",warning=FALSE}
plot(model.random.forest)
legend("right", legend = c("OOB Error", "FPR", "FNR"),lty = c(1,2,3), col = c("black", "red", "green"))
```

The plot above presents the Out Of Bag error (black line) when the number of trees increase. An interesting thing that can be seen is that the OOB error is stabilized for number of trees equals to 500 which is the default value for the randomForest function. The green line is the False Negative Rate and is high compared to red line, which is the False Positive Rate. The reason why the green line has high error values is due to the imbalance of the data. 


```{r, eval = TRUE, fig.width=7,fig.height=6, fig.align="center", fig.cap="Variable Importance", fig.pos="H",warning=FALSE}
varImpPlot(model.random.forest)
```
The left plot, where the x axis is the MeanDecreaseAccuracy, indicates how much the accuracy decreases if we remove that variable. It is observed that removing the variable duration the accuracy decreases by a lot compared to the variable loan. 
The right plot, where the x axis is the MeanDecreaseGini, indicates the importance of each variable based on the gini impurity index, used for the calculation of splits in tree. The variable duration is the most important variable and it remains the same as in the left plot. However, the least important variable changes and it is the variable default. 


## Question 2(c)

In this question, we try to improve the misclassification error of the “yes” clients (by keeping the overall misclassificatione error still small) with different strategies. We modify the parameters: sampsize, classwt, cutoff and strata in the randomForest() function.

### Sampsize
The parameter sampsize defines the size or the sizes of sample to draw for the creations of the trees. In our case where the data are imbalances, we could define the number of samples that belong to class "yes" or class "no", through the parameter sampsize. 

We randomly select 100 samples for the class "no" and 100 samples for the class "yes" and check if the misclassification error for the class "yes" is reduced.

```{r, eval = TRUE}
model.random.forest <- randomForest(y~.,data=bank, subset=train,sampsize = c(100,100))

predictions <- predict(model.random.forest,newdata=bank[test,], type="class")
actual <- bank[test,]$y
TAB.forest <- table(actual,predictions)
TAB.forest

misclassification.error.forest <- 1-sum(diag(TAB.forest))/sum(TAB.forest)
cat("The misclassification rate is: ", misclassification.error.forest)
cat("\n")
cat("The misclassification rate for the yes clients is: ", 
    1 - TAB[2,2]/(TAB[1,2]+TAB[2,1]+TAB[2,2]))
```


### Classwt

The parameter classwt assigns weights to the two classes. The weights that were used are from the question 1(g)
```{r, eval = TRUE}
model.random.forest <- randomForest(y~.,data=bank[train,],classwt = c(w0,w1))

predictions <- predict(model.random.forest,newdata=bank[test,], type="class")
actual <- bank[test,]$y
TAB.forest <- table(actual,predictions)
TAB.forest

misclassification.error.forest <- 1-sum(diag(TAB.forest))/sum(TAB.forest)
cat("The misclassification rate is: ", misclassification.error.forest)
cat("\n")
cat("The misclassification rate for the yes clients is: ", 
    1 - TAB[2,2]/(TAB[1,2]+TAB[2,1]+TAB[2,2]))
```

### Cutoff

The cutoff parameter is only used for classfication. More specifically, the cutoff is a A vector of length equal to number of classes. The ‘winning’ class for an observation is the one with the maximum ratio of proportion of votes to cutoff. Default is 1/k where k is the number of classes (k=2 in our case) (i.e., majority vote wins). We randomly select cutoff = c(0.3,0.7). Thus:

```{r, eval = TRUE}
model.random.forest <- randomForest(y~.,data=bank, subset=train,cutoff = c(0.3,0.7))

predictions <- predict(model.random.forest,newdata=bank[test,], type="class")
actual <- bank[test,]$y
TAB.forest <- table(actual,predictions)
TAB.forest

misclassification.error.forest <- 1-sum(diag(TAB.forest))/sum(TAB.forest)
cat("The misclassification rate is: ", misclassification.error.forest)
cat("\n")
cat("The misclassification rate for the yes clients is: ", 
    1 - TAB[2,2]/(TAB[1,2]+TAB[2,1]+TAB[2,2]))
```

### Strata

The strata parameter is responsible for the stratified sampling.

```{r, eval = TRUE}
model.random.forest <- randomForest(y~.,data=bank[train,],strata = bank$y[train])

predictions <- predict(model.random.forest,newdata=bank[test,], type="class")
actual <- bank[test,]$y
TAB.forest <- table(actual,predictions)
TAB.forest

misclassification.error.forest <- 1-sum(diag(TAB.forest))/sum(TAB.forest)
cat("The misclassification rate is: ", misclassification.error.forest)
cat("\n")
cat("The misclassification rate for the yes clients is: ", 
    1 - TAB[2,2]/(TAB[1,2]+TAB[2,1]+TAB[2,2]))
```

Overall, non of the above approaches improve the misclassification rate for the yes clients. The error rate remanes the same with all different strategies. 





