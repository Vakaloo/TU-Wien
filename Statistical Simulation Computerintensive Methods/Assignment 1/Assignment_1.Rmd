---
title: "Assignment 1 - Introduction to Simulation with Variance Estimation"
author: "Konstantinos Vakalopoulos 12223236"
date: "2023-10-11"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Reproduce the example from the first lecture and document your results using R Markdown.

## Task 1

Compare the 4 algorithms against R's 'var' function as a gold standard regarding the quality of their estimates.
 
+ Implement all variants of variance calculation as functions.
+ Write a wrapper function which calls the different variants.

Below, all the 5 algorithms for the variance calculation are presented as functions. Algorithm 0 is the gold standard (var function from R), algorithm 1 is the normal calculation of variance, algorithm 2 is the excel implementation, algorithm 3 is the shift algorithm and algorithm 4 is the online implementation.

```{r, echo=TRUE}
##Algorithm 0##
gold_standard <- function(x){
  return(var(x))
}
```

```{r, echo=TRUE}
##Algorithm 1##
precise <- function(x){
  sample_mean <- sum(x)/length(x)
  variance <- sum((x-sample_mean)^2)/(length(x)-1)
  return(variance)
}

```

```{r, echo=TRUE}
##Algorithm 2##
excel <- function(x){
  P1 <- sum(x^2)
  P2 <- (sum(x))^2/length(x)
  variance <- (P1-P2)/(length(x)-1)
  return(variance)
}

```

```{r, echo=TRUE}
##Algorithm 3##
shift <- function(x, c){
  P1 <- sum((x-c)^2)
  P2 <- (sum(x-c))^2/length(x)
  variance <- (P1-P2)/(length(x)-1)
  return(variance)
}
```

```{r, echo=TRUE}
##Algorithm 4##
online <- function(x){
  # Calculate the mean and variance for the first and second element
  sample_mean <- (x[1]+x[2])/2
  variance <- ((x[1]-sample_mean)^2+(x[2]-sample_mean)^2)/(2-1)
  
  for (n in 3:length(x)){
    variance <- (n-2)/(n-1)*variance+(x[n]-sample_mean)^2/n
    sample_mean <- sample_mean + (x[n]-sample_mean)/n
  }
  return(variance)
}
```

Finally, the variance functions are being called using a wrapper function. We pass the data set x to the wrapper function, which was created using the command rnorm() and the seed was set to 12223236 (student ID).

```{r, echo=TRUE}
wrapper_function <- function(x){
  # Create a data frame for the variance result
  results <- data.frame(
    Method = c("Gold Standard", "Precise", 
               "Excel", "Shift", "Online"),
    Variance = c(
      gold_standard(x),
      precise(x),
      excel(x),
      shift(x, x[1]),
      online(x)
    )
  )
  return(results)
}

set.seed(12223236)
x <- rnorm(100)
# Compare variance calculation methods
comparison_results <- wrapper_function(x)
```

The library(knitr) is used for good representation of the tables

```{r, echo=TRUE, warning=FALSE, results='asis'}
library(knitr) # this library is used for good representation of the tables
kable(comparison_results, format = "markdown", caption = "Variances")
```


## Task 2

Compare the computational performance of the 4 algorithms against R's 'var' function as a gold standard and summarise them in tables and graphically.

For this task, library microbenchmark was installed and used in order to compare computational performance of the 4 algorithms against R's 'var' function. Furthermore, the two simulated data sets, x1, x2, from the slides, are going to be used not only for the computational performance but the comparison using the of the 4 algorithms with the gold standard using the operator “==” and the functions identical() and all.equal(). 

First we create the 2 simulated data sets (x1, x2)

```{r, echo=TRUE}
set.seed(12223236)
x1 <- rnorm(100)
set.seed(12223236)
x2 <- rnorm(100, mean=1000000)
```

Regarding the first data set:

```{r, echo=TRUE, warning=FALSE, results='asis'}
# install.packages("microbenchmark")
library(microbenchmark)

# Table Summarize
mb <- microbenchmark(
  "Gold Standard" = gold_standard(x1),
  "Precise" = precise(x1),
  "Excel" = excel(x1),
  "Shift" = shift(x1,x[1]),
  "Online" = online(x1),
  times = 100
)
kable(summary(mb), format = "markdown", caption = "Computational Performance of x1 data set")
```

According to the table, the var function from R and the online implementation perform the worst. The performance of other 3 algorithms (precise, excel, shift) is roughly equivalent. The same is observed in the boxplot below. 

```{r, echo=TRUE,fig.width=6.5,fig.height=4, fig.align='center'}
#Graphically summarize
boxplot(mb, main="Execution Time Comparison of x1 data set", 
        ylab="Time (milliseconds)")
```

Regarding the second data set:

```{r, echo=TRUE, warning=FALSE, results='asis'}
# install.packages("microbenchmark")
library(microbenchmark)

# Table Summarize
mb <- microbenchmark(
  "Gold Standard" = gold_standard(x2),
  "Precise" = precise(x2),
  "Excel" = excel(x2),
  "Shift" = shift(x2,x[1]),
  "Online" = online(x2),
  times = 100
)
kable(summary(mb), format = "markdown", caption = "Computational Performance of x2 data set")
```

```{r, echo=TRUE,fig.width=6.5,fig.height=4, fig.align='center'}
#Graphically summarize
boxplot(mb, main="Execution Time Comparison of x2 data set", 
        ylab="Time (milliseconds)")
```

The same results, with small differences, are observed, also, in the second data set. 



## Task 3

Investigate the scale invariance property for different values and argue why the mean is performing best as mentioned with the condition number.

+ Compare the results according to the instructions provided by Comparison I and Comparison II of the slides.
+ Provide your results in table format and graphical format comparable to the example in the slides.

Regarding the investigation of the scale invariance property for different values, the shifted algorithm was selected, as mentioned in the slide 20, using 6 different values as the condition number. Overall, we have 6 simulations where in one simulation the mean of the sample is used as the condition number in order to prove that the mean gives the best condition number. The rest of the values were drawn from the summary of the sample x (min, max, median, 1st and 3rd quartile)

```{r, echo=TRUE, warning=FALSE, results='asis'}
# Table Summarize for the scale invariance property for different values
mb_shift <- microbenchmark(
  "Min" = shift(x, summary(x)[1]),
  "1st Qu" = shift(x,summary(x)[2]),
  "Median" = shift(x,summary(x)[3]),
  "Mean" = shift(x,summary(x)[4]),
  "3rd Qu" = shift(x,summary(x)[5]),
  "Max" = shift(x,summary(x)[6]),
  times = 100
)
kable(summary(mb_shift), format = "markdown", caption = "Computational Performance")
```



Consequently, we compare the results of the 4 algorithms with the gold standard using the operator "==" and the functions identical() and all.equal(). Regarding the x1 data set:

```{r, echo=TRUE}
# First data set Comparison 1
gold<- gold_standard(x1)
rest <- c(precise(x1),excel(x1),shift(x1, x1[1]),online(x1))

gold == rest
# Function identical is used
for (v in rest){
  print(identical(gold,v))
}

# Function all.equal is used
for (v in rest){
  print(all.equal(gold,v))
}
```

According to the results, the gold standard variance is not equal with excel and shift implementation using the operator "==" and the identical function. On the other hand, the all.equal() function proves that all the calculations are equal. 

Regarding the x2 data set:

```{r, echo=TRUE}
# Second data set Comparison 1
gold<- gold_standard(x2)
rest <- c(precise(x2),excel(x2),shift(x2, x2[1]),online(x2))

gold == rest
# Function identical is used
for (v in rest){
  print(identical(gold,v))
}

# Function all.equal is used
for (v in rest){
  print(all.equal(gold,v))
}
```

According to the results, the gold standard variance is not equal with excel and online implementation using the operator "==" and the identical function. On the other hand, the all.equal() function proves that all the calculations are equal except the excel implementation where the Mean relative difference is 0.0001883182. 

In this part of this exercise, we calculate the computational performance of the 2 data sets and we also visualize it using boxplots.




